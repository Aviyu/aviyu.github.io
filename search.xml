<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[go语言channel详解]]></title>
    <url>%2F2018%2F08%2F07%2Fgolang%2Fchan%2F</url>
    <content type="text"><![CDATA[声明chan12345678//声明一个双向chanvar commanChan chan interface&#123;&#125;//声明一个双向channel的channelvar commanChan chan chan interface&#123;&#125;//声明一个只读的channelvar writeOnlyChan chan&lt;- interface&#123;&#125;//声明一个只写的channelvar readOnlyChan &lt;-chan interface&#123;&#125; make chan123456//不带缓冲区的chanoneChan := make(chan interface&#123;&#125;)//带缓冲区的chantwoChan := make(chan interface&#123;&#125;,1)//带10个缓冲区的chanthreeChan := make(chan interface&#123;&#125;,10) 无缓冲的channel无缓冲的chan是同步的，就是说无论是『读』还是『写』，如果chan没有其它协程在进行相应相反方向的的『写』或者『读』，都会造成阻塞，简单的说就是chan如果不是同时有读写两种操作就会阻塞。 （运行时读写必定一前一后，这里所谓的『同时』只是一个时间点） 运行时报错举例： 12345678910111213141516package mainimport "fmt"func main() &#123; c := make(chan interface&#123;&#125;) fmt.Println(&lt;-c) c &lt;- "hello chan"&#125; //输出//fatal error: all goroutines are asleep - deadlock!//// goroutine 1 [chan receive]:// main.main()// ......./main.go:7 +0x5f// exit status 2 1234567891011121314151617package mainimport "fmt"func main() &#123; c := make(chan interface&#123;&#125;) c &lt;- "hello chan" fmt.Println(&lt;-c)&#125;//输出//fatal error: all goroutines are asleep - deadlock!//// goroutine 1 [chan receive]:// main.main()// ......./main.go:7 +0x5f// exit status 2 上面两段代码都会在第7行阻塞并且报错：死锁（deadlock）错误！因为在第7行读和写都会阻塞，第8行的代码运行不到，第7行代码永久阻塞。 如何让上面的代码正常执行呢？修正的方法如下：12345678910111213package mainimport "fmt"func main() &#123; c := make(chan interface&#123;&#125;) go func()&#123; c &lt;- "hello chan" &#125;() fmt.Println(&lt;-c)&#125;//输出：//hello chan 1234567891011121314151617package mainimport "fmt"func main() &#123; c := make(chan interface&#123;&#125;) go func() &#123; fmt.Println("r") fmt.Println(&lt;-c) &#125;() fmt.Println("w") c &lt;- "hello chan"&#125;//输出：// w// r// hello chan 原理很简单：如第二段代码所示，这里我加了两行代码来清晰的了解代码运行过程，先是运行main中的channel进行写操作，然后阻塞在第12行，然后运行的第7行的goroutine中的读操作并打印。 带缓冲的channel刚才说不带缓冲的channel是同步的，那么带缓冲的channel是不是异步的呢？ 很抱歉，不是异步的，区别仅仅是多了个缓冲区而已。那么这个缓冲区怎么理解呢？ 我们以带一个缓冲区的channel为例，代码如下123456789101112131415package mainimport "fmt"func main() &#123; c := make(chan interface&#123;&#125;, 1) fmt.Println("w") c &lt;- "hello chan" fmt.Println("r") fmt.Println(&lt;-c) &#125;// 输出：// w// r// hello chan 唉？还说不是异步的，这不是在一个goroutine里跑的很好吗？打印出来了”hello chan”并且代码的第8行并没有阻塞。那么我们把代码稍稍改一下试试。 12345678910111213141516171819202122package mainimport "fmt"func main() &#123; c := make(chan interface&#123;&#125;, 1) fmt.Println("w") c &lt;- "hello chan" fmt.Println("w") c &lt;- "hello chan" fmt.Println("r") fmt.Println(&lt;-c) &#125;// 输出：// w// w// fatal error: all goroutines are asleep - deadlock!// goroutine 1 [chan send]:// main.main()// ........./main.go:12 +0x14a// exit status 2 当我们再读操作之前再加一个写操作的时候，报出了和之前无缓冲区channel一样的错误：deadlock。同样的，如果我们在最后加一个读操作一样会报错。这说明缓冲区的作用仅仅是缓冲区，即带缓冲区的channel有一个缓冲区暂时将读结果存起来了，在缓冲区充足的情况下未发生读操作之前不阻塞写操作，可以让当前的goroutine继续向下运行；但是当缓冲区满了之后，如果发生了写操作那么运行的行为和结果与不带缓冲区的channel是一样的。同样的如果缓冲区没有数据，进行读操作一样会阻塞。 就是这么简单，没有多复杂，带不带缓冲区跟异步同步没有关系，仅仅就是一个缓冲区，仅仅是在行为上有点同步和异步的样子。(看网上其他的文章说明这个的时候，差点把我整蒙圈了。囧) chan的读取一般读取123456789101112package mainimport "fmt"func main() &#123; c := make(chan interface&#123;&#125;, 3) c &lt;- "hello" v := &lt;-c fmt.Println(v)&#125;//输出：//hello 带关闭标记的读取1234567891011121314151617181920package mainimport "fmt"func main() &#123; c := make(chan interface&#123;&#125;, 3) c &lt;- "hello" close(c) for i := 2; i &gt; 0; i-- &#123; if v, ok := &lt;-c; ok &#123; fmt.Println(v) &#125; else &#123; fmt.Println("closed") &#125; &#125;&#125;//输出：//hello//closed for循环读取12345678910111213141516171819202122232425262728293031323334353637package mainimport ( "fmt" "time")var stop chan int = make(chan int)func main() &#123; c := make(chan interface&#123;&#125;, 3) go func() &#123; for i := 0; i &lt; 5; i++ &#123; time.Sleep(1 * time.Second) c &lt;- fmt.Sprintf("Hello %d", i) &#125; &#125;() go func() &#123; for i := 0; i &lt; 5; i++ &#123; fmt.Println(&lt;-c) &#125; stop &lt;- 0 &#125;() Listen() fmt.Println("stop")&#125;//此方法的作用：阻塞，让循环完成func Listen() &#123; &lt;-stop&#125;// 输出：// Hello 0// Hello 1// Hello 2// Hello 3// Hello 4// stop range读取12345678910111213141516171819202122232425262728293031package mainimport ( "fmt" "time")var stop chan int = make(chan int)func main() &#123; c := make(chan interface&#123;&#125;, 3) go func() &#123; for i := 0; i &lt; 5; i++ &#123; time.Sleep(1 * time.Second) c &lt;- fmt.Sprintf("Hello %d", i) &#125; close(c) &#125;() go func() &#123; for v := range c &#123; fmt.Println(v) &#125; stop &lt;- 0 &#125;() Listen() fmt.Println("stop")&#125;//此方法的作用：阻塞，让循环完成func Listen() &#123; &lt;-stop&#125; range无法像普通读取那样获取第二个参数(channel的close标记：”ok”)，当close之后，会自动跳出循环，如果不关闭，就会处于阻塞状态，等待数据。 select读取select比较强大，它会优先执行case中没有阻塞的case。 我这里总结了4个常用的case的类型： channel可读：channel可读则返回，没有写操作或者缓冲区为空则阻塞 channel可写：channel可写则返回，没有读操作或者缓冲区已满则阻塞 超时：超时之后返回，超时时间内阻塞 default：立即返回，永不阻塞 1234567891011121314151617181920212223242526272829303132333435363738394041package mainimport ( "fmt" "time")var stop chan int = make(chan int)func main() &#123; c := make(chan interface&#123;&#125;, 3) go func() &#123; for i := 0; i &lt; 5; i++ &#123; time.Sleep(3 * time.Second) c &lt;- fmt.Sprintf("Hello %d", i) &#125; close(c) &#125;() go func() &#123; LOOP: for &#123; select &#123; case &lt;-time.After(time.Second): fmt.Println("time out") case v, ok := &lt;-c: if !ok &#123; break LOOP &#125; else &#123; fmt.Println(v) &#125; &#125; &#125; stop &lt;- 0 &#125;() Listen() fmt.Println("stop")&#125;func Listen() &#123; &lt;-stop&#125; 说明：当for和select一起使用的时候只使用break是无法跳出for循环的，必须使用带标记的break或者goto语句才行。 关闭chanchan的关闭是指关闭chan的写入，可以继续读取。1234567891011121314151617181920212223242526package mainimport "fmt"func main() &#123; c := make(chan interface&#123;&#125;, 3) c &lt;- "hello" c &lt;- "chan" close(c) //c &lt;- "error" for i := 0; i &lt; 4; i++ &#123; if v, ok := &lt;-c; ok &#123; fmt.Println(v) &#125; else &#123; fmt.Println(v,"closed") &#125; &#125;&#125;//输出：// hello// chan// &lt;nil&gt; closed// &lt;nil&gt; closed//如果不注释第10行的话，就会报出下面的错误：//panic: send on closed channel 如果chan不关闭的话第12行代码就会阻塞，如果关闭并且chan中的数据全部取完，ok就会返回false，v就会返回nil。具体使用时，一定要弄清楚自己要表达的逻辑。]]></content>
      <categories>
        <category>技术</category>
        <category>golang</category>
      </categories>
      <tags>
        <tag>golang</tag>
        <tag>channel</tag>
        <tag>信道</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[分布式一致性算法]]></title>
    <url>%2F2018%2F08%2F06%2Fdistributed%2Fdistributed-algorithm%2F</url>
    <content type="text"><![CDATA[轮询算法(Round Robin)假设有一组服务器N台，S = {S1, S2, …, Sn}，一个指示变量i表示上一次选择的服务器ID。变量i被初始化为N-1。 1234567891011j = i;do&#123; j = (j + 1) mod n; if (W(Sj) &gt; 0) &#123; i = j; return Si; &#125;&#125; while (j != i);return NULL; 加权轮询调度算法(Weight Round Robin)假设有一组服务器S = {S0, S1, …, Sn-1}，W(Si)表示服务器Si的权值，一个指示变量i表示上一次选择的服务器，指示变量cw表示当前调度的权值，max(S)表示集合S中所有服务器的最大权值，gcd(S)表示集合S中所有服务器权值的最大公约数。变量i初始化为-1，cw初始化为零。 12345678910111213while (true) &#123; i = (i + 1) mod n; if (i == 0) &#123; cw = cw - gcd(S); if (cw &lt;= 0) &#123; cw = max(S); if (cw == 0) return NULL; &#125; &#125; if (W(Si) &gt;= cw) return Si; &#125; 源地址哈希(Source Hashing)目标地址hash(Destination Hashing)静态调度算法(static Schedu)动态调度算法(dynamic Schedu) 最少连接(Least-Connection Scheduling)加权最少连接(Weighted Least-Connection Scheduling)最少期望延迟(shortest expected delay scheduling)永不排队(Never Queue Scheduling)基于局部性的最少连接(Locality-Based Least Connections)基于局部性的带复制功能的最少连接(Locality-Based Least Connections with Replication)]]></content>
      <categories>
        <category>技术</category>
        <category>分布式</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>分布式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[算法之基础]]></title>
    <url>%2F2018%2F08%2F01%2Falgorithm%2Falgorithm-base%2F</url>
    <content type="text"><![CDATA[基本结构 顺序执行 循环执行 for while 递归 分支和跳转 if switch 数据结构 数组 链表 栈 队列 复杂的数据结构 树 集合 哈希和映射 图 算法思想 贪心算法 分治法 动态规划 穷举 盲目搜索 启发式搜索 剪枝策略]]></content>
      <categories>
        <category>技术</category>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[算法之数组]]></title>
    <url>%2F2018%2F08%2F01%2Falgorithm%2Falgorithm-array%2F</url>
    <content type="text"><![CDATA[数组的遍历顺序遍历算法复杂度：O(N)123456789#include &lt;stdio.h&gt;int main()&#123; int arr[3] = &#123;1,2,3&#125;; for(int i=0;i&lt;3;i++) &#123; printf("%d ",i); &#125;&#125; 输出：10 1 2 双层循环遍历全量的循环算法复杂度：O(N^2)12345678910111213#include &lt;stdio.h&gt;int main()&#123; int arr[3] = &#123;1,2,3&#125;; for(int i=0;i&lt;3;i++) &#123; for(int j=0;j&lt;3;j++) &#123; printf("%d:%d ",i,j); &#125; &#125; printf("\n");&#125; 输出：10:0 0:1 0:2 1:0 1:1 1:2 2:0 2:1 2:2 非重复的循环即如果1:0已经出现过了，那么0:1就不用再遍历一边了 算法复杂度：O(N!) –&gt; O(N^(N-1))12345678910111213#include &lt;stdio.h&gt;int main()&#123; int arr[3] = &#123;1,2,3&#125;; for(int i=0;i&lt;3;i++) &#123; for(int j=i;j&lt;3;j++) &#123; printf("%d:%d ",i,j); &#125; &#125; printf("\n");&#125; 输出：10:0 0:1 0:2 1:1 1:2 2:2 条件选择遍历算法复杂度：O(n)123456789101112131415161718192021222324#include &lt;stdio.h&gt;int main()&#123; int arr[7] = &#123;5,3,4,6,7,1,2&#125;; int n = sizeof(arr)/sizeof(arr[0]); //以上是模拟一个数组的输入 int start = 0; int end = n-start-1; while(start!=end) &#123; printf("%d:%d ",arr[start],arr[end]); //按照两边的大小舍弃小边遍历 //具体使用的时候可以按照实际逻辑选取 if (arr[start]&lt;arr[end]) &#123; start++; &#125; else &#123; end--; &#125; &#125; printf("\n");&#125; 输出：15,2 5,1 5,7 3,7 4,7 6,7]]></content>
      <categories>
        <category>技术</category>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[在Docker中运行kafka]]></title>
    <url>%2F2018%2F07%2F31%2Fdistributed%2Fkafka-install%2F</url>
    <content type="text"><![CDATA[需要安装zookeeper kafka1: image: wurstmeister/kafka ports: - "9092:9092" environment: KAFKA_ADVERTISED_HOST_NAME: localhost KAFKA_ZOOKEEPER_CONNECT: "zookeeper:2181" KAFKA_BROKER_ID: 1 KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 3 KAFKA_CREATE_TOPICS: "stream-in:1:1,stream-out:1:1" container_name: kafka kafka_manager: image: hlebalbau/kafka-manager:latest ports: - "9000:9000" environment: ZK_HOSTS: "zookeeper:2181" APPLICATION_SECRET: "random-secret" command: -Dpidfile.path=/dev/null container_name: kafka_manager]]></content>
      <categories>
        <category>技术</category>
        <category>分布式</category>
      </categories>
      <tags>
        <tag>分布式</tag>
        <tag>kafka</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[在Docker中运行zookeeper]]></title>
    <url>%2F2018%2F07%2F30%2Fdistributed%2Fzookeeper-install%2F</url>
    <content type="text"><![CDATA[在安装zookerkeeper之前，需要先安装docker和docker-compose工具 docker-compose.yml文件的内容如下： 123456789101112131415version: '3.1'services: zoo1: image: zookeeper restart: always ports: - 2181:2181 - 2888:2888 - 3888:3888 environment: ZOO_MY_ID: 1 ZOO_SERVERS: server.1=0.0.0.0:2888:3888 server.2=zoo2:2888:3888 server.3=zoo3:2888:3888 container_name: zookeeper 123456789101112131415version: '3.1'services: zoo2: image: zookeeper restart: always ports: - 2181:2181 - 2888:2888 - 3888:3888 environment: ZOO_MY_ID: 2 ZOO_SERVERS: server.1=zoo1:2888:3888 server.2=0.0.0.0:2888:3888 server.3=zoo3:2888:3888 container_name: zookeeper 123456789101112131415version: '3.1'services: zoo3: image: zookeeper restart: always ports: - 2181:2181 - 2888:2888 - 3888:3888 environment: ZOO_MY_ID: 3 ZOO_SERVERS: server.1=zoo1:2888:3888 server.2=zoo2:2888:3888 server.3=0.0.0.0:2888:3888 container_name: zookeeper 上面使用变量修改配置，如果需要修改配置文件，可以使用挂载 1234volumes: - /data/zookeeper/conf/zoo.cfg:/conf/zoo.cfg #配置文件路径 - /data/zookeeper/data:/data #数据目录 - /data/zookeeper/datalog:/datalog #日志目录 配置设置有以下变量：1234567ZOO_INIT_LIMITZOO_SYNC_LIMITZOO_MAX_CLIENT_CNXNSZOO_STANDALONE_ENABLEDZOO_MY_IDZOO_SERVERS 分别运行 1docker-compose up -d 即可]]></content>
      <categories>
        <category>技术</category>
        <category>分布式</category>
      </categories>
      <tags>
        <tag>分布式</tag>
        <tag>zookeeper</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[rabbitmq初探]]></title>
    <url>%2F2018%2F07%2F24%2Fdistributed%2Frabbitmq%2F</url>
    <content type="text"><![CDATA[部署利用docker镜像启动rabbitmq，其中management版本带有管理界面1234docker run -d --hostname my-rabbit --name some-rabbit \-p 5671:5671 -p 5672:5672 -p 15672:15672 -p 15671:15671 -p 25672:25672 \-v /data/rabbitmq-data/:/var/rabbitmq/lib \rabbitmq:3-management 启动之后就可以使用 http://localhost:15672 来访问了默认账号和密码都是guest 使用Golang链接生产者代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051package mainimport ( "log" "strconv" "time" "github.com/streadway/amqp")func failOnError(err error, msg string) &#123; if err != nil &#123; log.Fatalf("%s: %s", msg, err) &#125;&#125;func main() &#123; conn, err := amqp.Dial("amqp://guest:guest@localhost:5672/") failOnError(err, "Failed to connect to RabbitMQ") defer conn.Close() ch, err := conn.Channel() failOnError(err, "Failed to open a channel") defer ch.Close() q, err := ch.QueueDeclare( "hello", // name false, // durable false, // delete when unused false, // exclusive false, // no-wait nil, // arguments ) failOnError(err, "Failed to declare a queue") for i := 1; i &lt;= 200000; i++ &#123; body := "hello " + strconv.Itoa(i) + ":" + time.Now().Format("15:04:05") err = ch.Publish( "", // exchange q.Name, // routing key false, // mandatory false, // immediate amqp.Publishing&#123; ContentType: "text/plain", Body: []byte(body), &#125;) log.Printf(" [x] Sent %s", body) failOnError(err, "Failed to publish a message") &#125;&#125; 消费者12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455package mainimport ( "log" "github.com/streadway/amqp")func failOnError(err error, msg string) &#123; if err != nil &#123; log.Fatalf("%s: %s", msg, err) &#125;&#125;func main() &#123; conn, err := amqp.Dial("amqp://guest:guest@localhost:5672/") failOnError(err, "Failed to connect to RabbitMQ") defer conn.Close() ch, err := conn.Channel() failOnError(err, "Failed to open a channel") defer ch.Close() q, err := ch.QueueDeclare( "hello", // name false, // durable false, // delete when unused false, // exclusive false, // no-wait nil, // arguments ) failOnError(err, "Failed to declare a queue") msgs, err := ch.Consume( q.Name, // queue "", // consumer true, // auto-ack false, // exclusive false, // no-local false, // no-wait nil, // args ) failOnError(err, "Failed to register a consumer") forever := make(chan bool) go func() &#123; for d := range msgs &#123; log.Printf("Received a message: %s", d.Body) &#125; &#125;() log.Printf(" [*] Waiting for messages. To exit press CTRL+C") &lt;-forever&#125;]]></content>
      <categories>
        <category>技术</category>
        <category>分布式</category>
      </categories>
      <tags>
        <tag>消息队列</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一种套餐结构数据的数据库设计]]></title>
    <url>%2F2018%2F05%2F08%2Fdatabase%2Fpackage-design%2F</url>
    <content type="text"><![CDATA[商品数据库设计如下： 123456DROP TABLE IF EXISTS `product`;CREATE TABLE `product` ( `id` INT NOT NULL AUTO_INCREMENT PRIMARY KEY, `name` NVARCHAR(255) UNIQUE NOT NULL COMMENT '商品名称', `price` DECIMAL(12,2) DEFAULT 0 COMMENT '价格' ) ENGINE=InnoDB AUTO_INCREMENT=1 DEFAULT CHARSET=utf8 COMMENT='商品'; 比如下面是我们的商品 面条 茶叶蛋 油条 豆腐脑 豆浆 1234567INSERT INTO product(`name`,`price`)VALUES('面条',10),('茶叶蛋',2),('油条',5),('豆腐脑',5),('豆浆',7) 假设我们推出了一款套餐——油条+豆浆+茶叶蛋，并且取名叫油豆茶套餐 数据库设计如下：123456789101112131415DROP TABLE IF EXISTS `product`;CREATE TABLE `product` ( `id` INT NOT NULL AUTO_INCREMENT PRIMARY KEY, `package` INT NOT NULL DEFAULT 0 COMMENT '0.非套餐，1.套餐', `name` NVARCHAR(255) UNIQUE NOT NULL COMMENT '商品名称', `price` DECIMAL(12,2) DEFAULT 0 COMMENT '价格' ) ENGINE=InnoDB AUTO_INCREMENT=1 DEFAULT CHARSET=utf8 COMMENT='商品';DROP TABLE IF EXISTS `relation_product_package`; CREATE TABLE `relation_product_package` ( `id` INT NOT NULL AUTO_INCREMENT PRIMARY KEY, `package_id` INT NOT NULL COMMENT '套餐id', `product_id` INT NOT NULL COMMENT '商品id', `price` DECIMAL(11,2) NOT NULL COMMENT '价格' DEFAULT 0 ) ENGINE=INNODB AUTO_INCREMENT=1 DEFAULT CHARSET=UTF8 COMMENT='套餐关系'; 12345678INSERT INTO product(`package`,`name`,`price`)VALUES (1,'油豆茶套餐',11)INSERT INTO relation_product_package(`package_id`,`product_id`,`price`)VALUES(6,3,4),(6,5,6),(6,2,1) 我们的“油豆茶”既是一种套餐，又是一种商品，查询时我们可以1SELET * FROM product 查询出所有可售商品 我们也可以按照下面的Join查询得到套餐详情，我们甚至可以给套餐内的商品指定不同的价格（套餐价）： 12345678910SELECT p.name AS package_name, p.price AS package_price, p2.name AS product_name, p2.price AS origin_price,r.price AS package_priceFROM product p JOIN relation_product_package r ON r.package_id = p.id JOIN product p2 ON r.product_id = p2.id 结果如下： package_name package_price product_name origin_price package_price 油豆茶套餐 11.00 油条 5.00 4.00 油豆茶套餐 11.00 豆浆 7.00 6.00 油豆茶套餐 11.00 茶叶蛋 2.00 1.00]]></content>
      <categories>
        <category>技术</category>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>数据库</tag>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[alpine添加c++相关]]></title>
    <url>%2F2018%2F04%2F16%2Flinux%2Falpine-dockerfile%2F</url>
    <content type="text"><![CDATA[12345678FROM golang:alpineRUN echo http://mirrors.ustc.edu.cn/alpine/latest-stable/main &gt; /etc/apk/repositories; \echo http://mirrors.ustc.edu.cn/alpine/latest-stable/community &gt;&gt; /etc/apk/repositoriesRUN apk updateRUN apk add gcc musl-dev g++]]></content>
      <categories>
        <category>技术</category>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>alpine</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[利用acme生成免费的https有效证书]]></title>
    <url>%2F2018%2F04%2F13%2Fhttp%2Facme%2F</url>
    <content type="text"><![CDATA[安装1curl https://get.acme.sh | sh 没有curl工具，没关系，可以这样装1wget -O - https://get.acme.sh | sh 没有wget工具，没关系，可以这样装123git clone https://github.com/Neilpang/acme.sh.gitcd ./acme.sh./acme.sh --install 生成证书Nginx1acme.sh --issue -d example.com --nginx 1234acme.sh --install-cert -d example.com \--key-file /path/to/keyfile/in/nginx/key.pem \--fullchain-file /path/to/fullchain/nginx/cert.pem \--reloadcmd &quot;service nginx force-reload&quot; Apacke1acme.sh --issue -d example.com --apache 12345acme.sh --install-cert -d example.com \--cert-file /path/to/certfile/in/apache/cert.pem \--key-file /path/to/keyfile/in/apache/key.pem \--fullchain-file /path/to/fullchain/certfile/apache/fullchain.pem \--reloadcmd &quot;service apache2 force-reload&quot; 以下的命令会临时监听 80 端口，请确保执行该命令前 80 端口没有使用 利用网站根目录申请1acme.sh --issue -d example.com -w /home/wwwroot/example.com 没有网站，利用开放端口申请1acme.sh --issue -d example.com --standalone --httpport 88 DNS API12345export CF_Key=&quot;sdfsdfsdfljlbjkljlkjsdfoiwje&quot;export CF_Email=&quot;xxxx@sss.com&quot;acme.sh --issue -d example.com --dns dns_cf DNS manual1acme.sh --issue -d example.com --dns 安装证书1~/.acme.sh/acme.sh --installcert -d 域名 --fullchainpath /path/to/server.crt --keypath /path/to/server.key 更新证书证书会自动每60天更新一次，如果要手动更新可以如下1~/.acme.sh/acme.sh --renew -d 域名 --force 自动更新acme1acme.sh --upgrade --auto-upgrade 关闭自动更新acme1acme.sh --upgrade --auto-upgrade 0]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>https</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker快速创建ftp服务]]></title>
    <url>%2F2018%2F04%2F12%2Fdocker%2Fdocker-ftp%2F</url>
    <content type="text"><![CDATA[创建ftp文件夹1234mkdir ftpcd ftpmkdir ftpusers pure-ftpdcd .. 编辑docker-compose.yaml123456789101112version: "3"services: server: image: stilliard/pure-ftpd:hardened volumes: - "./ftpusers:/home/ftpusers" - "./pure-ftpd:/etc/pure-ftpd" ports: - "21:21" - "30000-30009:30000-30009" environment: PUBLICHOST: localhost 启动容器1docker-compose up -d 进入容器，添加ftp用户12345docker exec -it ftp_server_1 bashpure-pw useradd [username] -u ftpuser -d /home/ftpusers/[username]# 输入两次userpasswdpure-pw mkdbexit]]></content>
      <categories>
        <category>技术</category>
        <category>docker</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>ftp</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git根据地址自动选择代理的方法]]></title>
    <url>%2F2018%2F04%2F02%2Fgit%2Fgitconfig%2F</url>
    <content type="text"><![CDATA[本人在github上有repository，在公司的git库上也有些项目，因为代理问题经常要修改git的配置文件，最近因为切换过于频繁，所以找到了一个方法分享出来。访问github要经过代理才能正常访问：http://dev-proxy.xxx.com:8080 所以我把git的配置文件添加了代理：12345[https]proxy = http://dev-proxy.xxx.com:8080[http]proxy = http://dev-proxy.xxx.com:8080 访问code就不许要代理设置，所以要把上面的删除。要解决问题就是让GIT在访问github时过代理，在访问code时不过代理，但是git config中又没有no-proxy和passby-proxy这种设置。嘿嘿，解决方法如下：1234567891011[https]proxy = http://dev-proxy.xxx.com:8080[http]proxy = http://dev-proxy.xxx.com:8080[http &quot;http://git.xxx.com/&quot;]proxy = [https &quot;https://git.xxx.com/&quot;] proxy = 搞定！]]></content>
      <categories>
        <category>技术</category>
        <category>git</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[golang中Rows.Scan自动赋值的方法封装]]></title>
    <url>%2F2018%2F03%2F26%2Fgolang%2Frows_scan%2F</url>
    <content type="text"><![CDATA[golang中database/sql里的查询返回的rows对象赋值特别麻烦，要一个一个值得指针传入，那有没有自动识别的办法呢？有的！ 比如我们用json的Tag名称来对应字段名进行赋值:123456789101112131415161718192021222324func ToStructByJsonTag(rows *sql.Rows, structPtr interface&#123;&#125;) error &#123; v := reflect.ValueOf(structPtr) if v.Kind() != reflect.Ptr || v.Elem().Kind() != reflect.Struct &#123; return errors.New("dest should be a struct's pointer") &#125; e := v.Elem() t := e.Type() cols, err := rows.Columns() if err != nil &#123; return err &#125; var dest_scans = make([]interface&#123;&#125;, len(cols)) for i, c := range cols &#123; for j := 0; j &lt; t.NumField(); j++ &#123; if t.Field(j).Tag.Get("json") == c &#123; dest_scans[i] = e.Field(j).Addr().Interface() &#125; &#125; &#125; rows.Scan(dest_scans...) return nil&#125;]]></content>
      <categories>
        <category>技术</category>
        <category>golang</category>
      </categories>
      <tags>
        <tag>golang</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[govendor帮助说明]]></title>
    <url>%2F2018%2F03%2F21%2Fgolang%2Fgovendor%2F</url>
    <content type="text"><![CDATA[govendor是一个管理golang的依赖的package的工具1go get -u github.com/kardianos/govendor 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859govendor (v1.0.9): record dependencies and copy into vendor folder -govendor-licenses Show govendor&apos;s licenses. -version Show govendor version -cpuprofile &apos;file&apos; Writes a CPU profile to &apos;file&apos; for debugging. -memprofile &apos;file&apos; Writes a heap profile to &apos;file&apos; for debugging.Sub-Commands init Create the &quot;vendor&quot; folder and the &quot;vendor.json&quot; file. list List and filter existing dependencies and packages. add Add packages from $GOPATH. update Update packages from $GOPATH. remove Remove packages from the vendor folder. status Lists any packages missing, out-of-date, or modified locally. fetch Add new or update vendor folder packages from remote repository. sync Pull packages into vendor folder from remote repository with revisions from vendor.json file. migrate Move packages from a legacy tool to the vendor folder with metadata. get Like &quot;go get&quot; but copies dependencies into a &quot;vendor&quot; folder. license List discovered licenses for the given status or import paths. shell Run a &quot;shell&quot; to make multiple sub-commands more efficient for large projects. go tool commands that are wrapped: &quot;+status&quot; package selection may be used with them fmt, build, install, clean, test, vet, generate, toolStatus Types +local (l) packages in your project +external (e) referenced packages in GOPATH but not in current project +vendor (v) packages in the vendor folder +std (s) packages in the standard library +excluded (x) external packages explicitly excluded from vendoring +unused (u) packages in the vendor folder, but unused +missing (m) referenced packages but not found +program (p) package is a main package +outside +external +missing +all +all packages Status can be referenced by their initial letters.Package specifier &lt;path&gt;[::&lt;origin&gt;][&#123;/...|/^&#125;][@[&lt;version-spec&gt;]]Ignoring files with build tags, or excluding packages from being vendored: The &quot;vendor.json&quot; file contains a string field named &quot;ignore&quot;. It may contain a space separated list of build tags to ignore when listing and copying files. This list may also contain package prefixes (containing a &quot;/&quot;, possibly as last character) to exclude when copying files in the vendor folder. If &quot;foo/&quot; appears in this field, then package &quot;foo&quot; and all its sub-packages (&quot;foo/bar&quot;, …) will be excluded (but package &quot;bar/foo&quot; will not). By default the init command adds the &quot;test&quot; tag to the ignore list.If using go1.5, ensure GO15VENDOREXPERIMENT=1 is set.]]></content>
      <categories>
        <category>技术</category>
        <category>golang</category>
      </categories>
      <tags>
        <tag>golang</tag>
        <tag>govendor</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[二维码]]></title>
    <url>%2F2018%2F03%2F21%2Fqrcode%2F</url>
    <content type="text"><![CDATA[什么是二维码二维条码是指在一维条码的基础上扩展出另一维具有可读性的条码，使用黑白矩形图案表示二进制数据，被设备扫描后可获取其中所包含的信息 二维码的WIKI 常见的二维条码有： PDF417码 QR码 汉信码 颜色条码 EZ码 Aztec Code QuickMark Data Matrix QR二维码QR图码（全称为快速响应矩阵图码；英语：Quick Response Code）是二维条码的一种，于1994年由日本DENSO WAVE公司发明。QR来自英文Quick Response的缩写，即快速反应，因为发明者希望QR码可以让其内容快速被解码。QR码使用四种标准化编码模式（数字、字母数字、字节（二进制）和汉字）来存储数据 存储QR码一共提供40种不同版本存储密度的结构，对应指示图的“版本信息”，版本1为21×21模块（模块为QR码中的最小单元），每增加一个版本，长宽各增加4个模块，最大的版本40为177×177模块。 容错能力QR码有容错能力，QR码图形如果有破损，仍然可以被机器读取内容，最高可以到7%~30%面积破损仍可被读取。所以QR码可以被广泛使用在运输外箱上。 相对而言，容错率愈高，QR码图形面积愈大。所以一般折衷使用15%容错能力。 档次 修正 L档次 7%的字码可被修正 M档次 15%的字码可被修正 Q档次 25%的字码可被修正 H档次 30%的字码可被修正]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>二维码</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[神]]></title>
    <url>%2F2018%2F03%2F12%2Fphilosophy%2Ffish%2F</url>
    <content type="text"><![CDATA[鱼缸里，小鱼：这个世界很奇妙啊，当我们饿的时候，食物就从天而降了。当水质变差的时候，水就自动变成了清水……大鱼：你认为这是奇妙的自然规律么?其实所有的规律背后，都有一个操纵的力量。这，来自神。小鱼：你说的神在哪里?我怎么没见过。我游遍了鱼缸的每一个角落。大鱼：他不在鱼缸里。甚至不在水里小鱼：他不在水里，怎么呼吸呢?_大鱼：他呼吸不用水，可以直接呼吸空气 _小鱼：可是他为什么要白白给我们食物呢?我听老鱼说，食物匮乏的时候，我们为了获得食物，甚至要付出生命的代价。可是你说的这个神却白白给我们宝贵的食物。这怎么可能?大鱼：神是万能的，所以，神供给我们食物，很容易。小鱼：如果神真的存在，那么神是哪来的?大鱼：不能因为我们无法理解神是哪来的，就否认神的存在。甚至有一种可能，那就是，神都未必知道自己是哪来的。况且我们是鱼，我们的智商无法理解神的状态，即使告诉我们，我们也听不懂。]]></content>
      <categories>
        <category>思考</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[CentOS7安装Kubernetes]]></title>
    <url>%2F2018%2F02%2F27%2Fdocker%2Fkubernetes-cluster%2F</url>
    <content type="text"><![CDATA[安装docker123456789101112131415161718yum install -y yum-utils \ device-mapper-persistent-data \ lvm2yum-config-manager \ --add-repo \ https://download.docker.com/linux/centos/docker-ce.repoyum install -y --setopt=obsoletes=0 \ docker-ce-17.03.2.ce-1.el7.centos \ docker-ce-selinux-17.03.2.ce-1.el7.centosmkdir /etc/dockertouch /etc/docker/daemon.jsoncat &lt;&lt;EOF &gt; /etc/docker/daemon.json&#123; &quot;exec-opts&quot;: [&quot;native.cgroupdriver=systemd&quot;]&#125;EOFsystemctl start dockersystemctl enable docker.service 安装kubeadm12345678910111213141516171819systemctl disable firewalldsystemctl stop firewalldsed -i &apos;s/SELINUX=enforcing/SELINUX=disabled/g&apos; /etc/selinux/configecho 1 &gt; /proc/sys/net/bridge/bridge-nf-call-iptablesecho 1 &gt; /proc/sys/net/bridge/bridge-nf-call-ip6tables cat &lt;&lt;EOF &gt; /etc/yum.repos.d/kubernetes.repo[kubernetes]name=Kubernetesbaseurl=https://packages.cloud.google.com/yum/repos/kubernetes-el7-x86_64enabled=1gpgcheck=1repo_gpgcheck=1gpgkey=https://packages.cloud.google.com/yum/doc/yum-key.gpg https://packages.cloud.google.com/yum/doc/rpm-package-key.gpgEOFsetenforce 0yum install -y kubelet kubeadm kubectl sed -i &apos;/ExecStart=$/iEnvironment=&quot;KUBELET_EXTRA_ARGS=--fail-swap-on=false&quot;&apos; /etc/systemd/system/kubelet.service.d/10-kubeadm.confsystemctl daemon-reload systemctl enable kubelet.service Master12345678kubeadm init \ --kubernetes-version=v1.9.0 \ --pod-network-cidr=10.244.0.0/16 \ # 这里要根据后面使用的网络组件设置 --apiserver-advertise-address=192.168.123.88 \ --ignore-preflight-errors=Swap mkdir -p $HOME/.kubesudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/configsudo chown $(id -u):$(id -g) $HOME/.kube/config 网络有Calico、Cannal、Flannel、Kube-router、Romana、Weave Net等推荐使用Calico 123# Calico# --pod-network-cidr=192.168.0.0/16 to kubeadm initkubectl apply -f https://docs.projectcalico.org/v3.0/getting-started/kubernetes/installation/hosted/kubeadm/1.7/calico.yaml 123# Flannel # --pod-network-cidr=10.244.0.0/16 to kubeadm initkubectl apply -f https://raw.githubusercontent.com/coreos/flannel/v0.9.1/Documentation/kube-flannel.yml Node在节点上直接运行join加入master中 123kubeadm join --token 8749e1.f6002af5eafc5bb6 192.168.123.88:6443 \--discovery-token-ca-cert-hash sha256:0d7d50582cfdcfb9f5a32c0f919d0317942f66d66345ebdf37f0f9bab1140af7 \--ignore-preflight-errors=Swap dashboard123456kubectl create -f https://raw.githubusercontent.com/kubernetes/heapster/master/deploy/kube-config/influxdb/grafana.yamlkubectl create -f https://raw.githubusercontent.com/kubernetes/heapster/master/deploy/kube-config/influxdb/heapster.yamlkubectl apply -f https://raw.githubusercontent.com/kubernetes/heapster/master/deploy/kube-config/rbac/heapster-rbac.yaml# install dashboardkubectl create -f https://raw.githubusercontent.com/kubernetes/dashboard/master/src/deploy/kubernetes-dashboard.yaml `]]></content>
      <categories>
        <category>技术</category>
        <category>docker</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[dva2]]></title>
    <url>%2F2018%2F02%2F22%2Ffrontend%2Fdva2%2F</url>
    <content type="text"><![CDATA[dva@2.0发布了，学习一下。下面是我安装的最新的dva-cli的版本1234$ dva -vdva-cli version 0.9.2 dva version 2.1.0roadhog version 2.2.0 roaldhog也更新到了2.2.0版本相比较之前的版本有一个巨大的改动： 原来的.roadhogrc文件用.webpackrc文件代替 集成antd的写法变成了这样12345&#123; "extraBabelPlugins": [ ["import", &#123; "libraryName": "antd", "libraryDirectory": "es", "style": "css" &#125;] ]&#125; 如果要使用transform-runtime，因为下载的@babel的版本为@babel/core@7.0.0-beta.40，所以extraBabelPlugins的设置写法有变化，而且不用下载安装babel-plugin-transform-runtime和babel-runtime了123456&#123; "extraBabelPlugins": [ "@babel/plugin-transform-runtime", ["import", &#123; "libraryName": "antd", "libraryDirectory": "es", "style": "css" &#125;] ]&#125; 之前是这样123456&#123; "extraBabelPlugins": [ "transform-runtime", ["import", &#123; "libraryName": "antd", "libraryDirectory": "es", "style": "css" &#125;] ]&#125;]]></content>
      <categories>
        <category>技术</category>
        <category>javascript</category>
      </categories>
      <tags>
        <tag>前端</tag>
        <tag>javascript</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[cookie、LocalStorage和sessionStorage之间的区别]]></title>
    <url>%2F2018%2F02%2F22%2Ffrontend%2Fwebstorage%2F</url>
    <content type="text"><![CDATA[cookie、LocalStorage和sessionStorage都是保存在浏览器端，且同源的。 cookie数据可以在请求中携带，能够在浏览器和服务端间来回传递。存储大小不超过4k。有效时间为设置的时间 LocalStorage只客户端存储，大小约为5M，永久有效。 sessionStorage只客户端存储，大小约为5M，当前浏览器窗口关闭前有效。 web storage支持事件通知]]></content>
      <categories>
        <category>技术</category>
        <category>javascript</category>
      </categories>
      <tags>
        <tag>前端</tag>
        <tag>javascript</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[安装kubernetes单机环境]]></title>
    <url>%2F2018%2F02%2F09%2Fdocker%2Fkubernetes-single%2F</url>
    <content type="text"><![CDATA[安装VirtualBox从官方查看安装说明Download VirtualBox for Linux Hosts在最下方有Oracle Linux / RHEL的yum的repo资源链接打开之后如下：1234567[virtualbox]name=Oracle Linux / RHEL / CentOS-$releasever / $basearch - VirtualBoxbaseurl=http://download.virtualbox.org/virtualbox/rpm/el/$releasever/$basearchenabled=1gpgcheck=1repo_gpgcheck=1gpgkey=https://www.virtualbox.org/download/oracle_vbox.asc 在/etc/yum.repos.d/中创建VirutalBox.repo文件并将上面的内容复制到文件中保存 更新yum缓存12yum clean allyum makecache 安装1yum install VirtualBox-5.2 安装kubectlkubectl就是一个可运行的二进制文件，工具命令，下载下来放到系统path里就可以了。 macOS可以使用下面的命令安装1curl -LO https://storage.googleapis.com/kubernetes-release/release/`curl -s https://storage.googleapis.com/kubernetes-release/release/stable.txt`/bin/darwin/amd64/kubectl 其他系统的安装可以查看官方的kubectl安装文档 安装minikubeminikube是一个单机的kubernetes的学习联系环境，可以在github上查看他的官方说明 macOS1brew cask install minikube Linux1curl -Lo minikube https://storage.googleapis.com/minikube/releases/latest/minikube-linux-amd64 &amp;&amp; chmod +x minikube &amp;&amp; sudo mv minikube /usr/local/bin/ Windows下载 minikube-windows-amd64.exe 文件，重命名为minikube.exe，并把它放在系统path里。 以上就是安装的部分，下面我就可以使用了 启动minikube1minikube start minikube启动的默认虚拟机是VirtualBox，如过想使用其他的虚拟机可以使用命令 1minikube start --vm-driver=xxx minikube支持的虚机种类很多，在Linux系统上还可以不使用虚拟机，如下： virtualbox vmwarefusion KVM2 KVM hyperkit xhyve hyperv none 执行命令之后就会启动集群12345678910111213Starting local Kubernetes v1.9.0 cluster...Starting VM...Getting VM IP address...Moving files into cluster...Downloading localkube binary 162.41 MB / 162.41 MB [============================================] 100.00% 0s 0 B / 65 B [----------------------------------------------------------] 0.00% 65 B / 65 B [======================================================] 100.00% 0sSetting up certs...Connecting to cluster...Setting up kubeconfig...Starting cluster components...Kubectl is now configured to use the cluster.Loading cached images from config file.]]></content>
      <categories>
        <category>技术</category>
        <category>docker</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[jupyter的快捷键]]></title>
    <url>%2F2018%2F02%2F01%2Fjupytershortcut%2F</url>
    <content type="text"><![CDATA[Jupyter Notebook 的快捷键Jupyter Notebook 有两种键盘输入模式。编辑模式，允许你往单元中键入代码或文本；这时的单元框线是绿色的。命令模式，键盘输入运行程序命令；这时的单元框线是灰色。 命令模式 (按键 Esc 开启)Enter : 转入编辑模式Shift-Enter : 运行本单元，选中下个单元Ctrl-Enter : 运行本单元Alt-Enter : 运行本单元，在其下插入新单元Y : 单元转入代码状态M :单元转入markdown状态R : 单元转入raw状态1 : 设定 1 级标题2 : 设定 2 级标题3 : 设定 3 级标题4 : 设定 4 级标题5 : 设定 5 级标题6 : 设定 6 级标题Up : 选中上方单元K : 选中上方单元Down : 选中下方单元J : 选中下方单元Shift-K : 扩大选中上方单元Shift-J : 扩大选中下方单元A : 在上方插入新单元B : 在下方插入新单元X : 剪切选中的单元C : 复制选中的单元Shift-V : 粘贴到上方单元V : 粘贴到下方单元Z : 恢复删除的最后一个单元D,D : 删除选中的单元Shift-M : 合并选中的单元Ctrl-S : 文件存盘S : 文件存盘L : 转换行号O : 转换输出Shift-O : 转换输出滚动Esc : 关闭页面Q : 关闭页面H : 显示快捷键帮助I,I : 中断Notebook内核0,0 : 重启Notebook内核Shift : 忽略Shift-Space : 向上滚动Space : 向下滚动 编辑模式 ( Enter 键启动)Tab : 代码补全或缩进Shift-Tab : 提示Ctrl-] : 缩进Ctrl-[ : 解除缩进Ctrl-A : 全选Ctrl-Z : 复原Ctrl-Shift-Z : 再做Ctrl-Y : 再做Ctrl-Home : 跳到单元开头Ctrl-Up : 跳到单元开头Ctrl-End : 跳到单元末尾Ctrl-Down : 跳到单元末尾Ctrl-Left : 跳到左边一个字首Ctrl-Right : 跳到右边一个字首Ctrl-Backspace : 删除前面一个字Ctrl-Delete : 删除后面一个字Esc : 进入命令模式Ctrl-M : 进入命令模式Shift-Enter : 运行本单元，选中下一单元Ctrl-Enter : 运行本单元Alt-Enter : 运行本单元，在下面插入一单元Ctrl-Shift– : 分割单元Ctrl-Shift-Subtract : 分割单元Ctrl-S : 文件存盘Shift : 忽略Up : 光标上移或转入上一单元Down :光标下移或转入下一单元 作者：深思海数_willschang链接：https://www.jianshu.com/p/050a427746c7來源：简书]]></content>
      <categories>
        <category>技术</category>
        <category>python</category>
      </categories>
      <tags>
        <tag>jupyter</tag>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[在Docker中运行gocd]]></title>
    <url>%2F2018%2F01%2F25%2Fgocd%2F</url>
    <content type="text"><![CDATA[运行gocd容器gocd是一个持续集成的工具，可视化效果非常好 运行gocd-server12345docker run -d --name server \-p8153:8153 -p8154:8154 \-v /path/to/godata:/godata \-v /path/to/go:/home/go \gocd/gocd-server:v18.1.0 我们就可以通过http://go-server-ip:8153来访问gocd-server的web了 运行gocd-agent1234567docker run -d --name gocd \-e AGENT_AUTO_REGISTER_KEY=53f57d90-c749-4758-b430-5af341117b0e \-e AGENT_AUTO_REGISTER_RESOURCES=diagnosis,bj \-e AGENT_AUTO_REGISTER_ENVIRONMENTS=bj \-e AGENT_AUTO_REGISTER_HOSTNAME=diagnosis_bj \-e GO_SERVER_URL=https://go-server-ip:8154/go \ gocd/gocd-agent-centos-7:v18.1.0 其中AGENT_AUTO_REGISTER_KEY是在gocd-server的配置中。执行完之后，就可以在web中看到添加的agent。 安装插件12cd /path/to/godata/plugins/externalwget https://github.com/gocd-contrib/script-executor-task/releases/download/0.3/script-executor-0.3.0.jar DOOD我们通常希望在agent中执行docker命令在宿主中建立镜像运行容器网上大家把这种技术称之为DOOD（docker outside of docker）。docker命令只能在root权限下执行，但是gocd的脚本是在go用户下运行的所以会报错，解决办法就是想办法让脚本切换到root下运行脚本，具体办法如下： 创建su文件su的文件内容如下1234567891011121314#%PAM-1.0auth sufficient pam_rootok.so# Uncomment the following line to implicitly trust users in the &quot;wheel&quot; group.auth sufficient pam_wheel.so trust use_uid# Uncomment the following line to require a user to be in the &quot;wheel&quot; group.auth required pam_wheel.so use_uidauth substack system-authauth include postloginaccount sufficient pam_succeed_if.so uid = 0 use_uid quietaccount include system-authpassword include system-authsession include system-authsession include postloginsession optional pam_xauth.so 创建dockerfile制作dood-gocd镜像1234567891011121314FROM gocd/gocd-agent-centos-7:v18.1.0RUN yum install -y yum-utils \ device-mapper-persistent-data \ lvm2RUN yum-config-manager \ --add-repo \ https://download.docker.com/linux/centos/docker-ce.repoRUN yum install -y docker-ceRUN yum -y install sudoRUN echo 'go ALL=(ALL) NOPASSWD:ALL' &gt;&gt; /etc/sudoersRUN gpasswd -a go wheelCOPY su /etc/pam.d/suRUN cp /usr/share/zoneinfo/Asia/Shanghai /etc/localtimeRUN echo 'Asia/Shanghai' &gt;/etc/timezone 这里的root方案就是在脚本中调用su root切换到root账户，并且取消输入密码。 12345678910docker build -t gocd-agent-dood .docker run -d --name gocd \-e AGENT_AUTO_REGISTER_KEY=53f57d90-c749-4758-b430-5af341117b0e \-e AGENT_AUTO_REGISTER_RESOURCES=diagnosis,bj \-e AGENT_AUTO_REGISTER_ENVIRONMENTS=bj \-e AGENT_AUTO_REGISTER_HOSTNAME=diagnosis_bj \-e GO_SERVER_URL=https://go-server-ip:8154/go \-v /var/run/docker.sock:/var/run/docker.sock \gocd-agent-dood 上面命令里的挂载就是把宿主机的docker.sock挂载到容器中，这样我们就能在gocd-agent-dood的容器中运行dock命名在宿主机上创建镜像运行容器了。 script如下： 1234su - root &lt;&lt;EOFxxxxxxxxx]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>持续集成</tag>
        <tag>运维</tag>
        <tag>gocd</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git的几个小技巧]]></title>
    <url>%2F2018%2F01%2F25%2Fgit%2Fgittips%2F</url>
    <content type="text"><![CDATA[让这个文件回到最近一次git commit或git add时的状态。1git checkout -- file github切换用户导致的permission deny问题解决办法123git credential-osxkeychain erasehost=github.comprotocol=https gitlab用https发布后在clone中出错1git config --global http.sslVerify false]]></content>
      <categories>
        <category>技术</category>
        <category>git</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Fetch怎么与后端互通Cookie]]></title>
    <url>%2F2018%2F01%2F25%2Ffrontend%2Ffetchcookie%2F</url>
    <content type="text"><![CDATA[fetch方法要想于后台专递cookie必须添加属性 1&#123;credentials: 'include'&#125; 注意：这个属性不是设置在headers里的 后台也必须设置一个header来配合 1&#123;"Access-Control-Allow-Credentials", "true"&#125;]]></content>
      <categories>
        <category>技术</category>
        <category>javascript</category>
      </categories>
      <tags>
        <tag>前端</tag>
        <tag>javascript</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Git只拉取部分代码]]></title>
    <url>%2F2018%2F01%2F24%2Fgit%2Fgitpartialpull%2F</url>
    <content type="text"><![CDATA[在某些情况下，我们会有从git上拉取部分文件的需求。 下面脚本就演示了如何从gitlab中只拉取需要的文件：123456789101112131415161718192021#!/bin/bash# 拼接git地址，并加上权限GITLAB_PROTOCOL=https://GITLAB_USER=xxxGITLAB_PASSWD=xxxGITLAB_ADDRESS=git.xxx.comGITLAB_GOURP=xxxxxxPROJECT_NAME=xxxxxxCLONE_ADDRESS=$GITLAB_PROTOCOL$GITLAB_USER':'$GITLAB_PASSWD'@'$GITLAB_ADDRESS'/'$GITLAB_GOURP'/'$PROJECT_NAME'.git'# 初始化git init # 添加源git remote add origin $CLONE_ADDRESS# 配置sparsecheckout为truegit config core.sparsecheckout true# 把要拉取的文件目录加入到.git/info/sparse-checkout文件中echo "dockerfile*" &gt;&gt; .git/info/sparse-checkoutecho "*.sh" &gt;&gt; .git/info/sparse-checkout# 拉取文件git pull origin master pull完成之后所有dockerfile和脚本文件就会被下载到本地。]]></content>
      <categories>
        <category>技术</category>
        <category>git</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx配置Http自动跳转https]]></title>
    <url>%2F2018%2F01%2F24%2Fhttp%2Fnginx-https%2F</url>
    <content type="text"><![CDATA[12345678910111213141516171819202122232425server &#123; listen 80; server_name domain.com; #告诉浏览器有效期内只准用 https 访问 add_header Strict-Transport-Security max-age=15768000; #永久重定向到 https 站点 return 301 https://$server_name$request_uri;&#125;server &#123; listen 443; server_name domain.com; ssl on; ssl_certificate /etc/nginx/keys/domain.com.pem; ssl_certificate_key /etc/nginx/keys/domain.com.key; # 代理 location / &#123; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-for $remote_addr; proxy_pass https://$server_name:2443; &#125;&#125;]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CSGO配置相关]]></title>
    <url>%2F2018%2F01%2F19%2Fcsgo%2Fcsgo-config%2F</url>
    <content type="text"><![CDATA[自动配置设置系统配置目录1....\Steam\SteamApps\common\Counter-Strike Global Offensive\csgo\cfg 系统配置目录中unbindall开头的文件将会在控制台内exec命令中自动显示 用户配置目录1....\Steam\userdata\&#123;steam帐号的32位ID&#125;\730\local\cfg 在用户配置目录中config_default.cfg是默认启动的配置文件在最后加上exec autoexec.cfg并将文件改为只读属性就可以每次自动执行autoexec.cfg中的命令了 启动参数-noforcemaccel -noforcemparms 去鼠标加速（-noforcemaccel -noforcemparms -noforcemspd）-freq 144 锁屏144HZ 根据个人显示器刷新率而异-novid 去除游戏开始动画效果，节省等待时间-high 高优先级-threads 4 四线程-preload 预读资源-tickrate 128 单机开服务器用的128tick-noforcemparms 游戏时禁用win键 配置参数参数显示net_graphpos 0 参数显示在界面左边net_graphpos 1 参数显示在界面右边net_graphpos 2 参数显示在界面中间net_graphheight 数值，数值越大，位置越高net_graphproportionalfont 0.9 将参数字体变小net_graphproportionalfont 1 将参数字体变大(默认) 自动跳扔alias “+jumpthrow” “+jump;-attack”alias “-jumpthrow” “-jump”bind “space” “+jumpthrow” 下蹲时不再抬起手臂cl_viewmodel_shift_left_amt “0”cl_viewmodel_shift_right_amt “0” 去除奔跑时武器的前后晃动cl_bob_lower_amt “0”cl_bobamt_lat “0”cl_bobamt_vert “0”]]></content>
      <categories>
        <category>游戏</category>
        <category>csgo</category>
      </categories>
      <tags>
        <tag>csgo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一个使用tensorflow实现的简单的神经网络的例子]]></title>
    <url>%2F2018%2F01%2F18%2Fpython%2Ftensorflow-simplenn%2F</url>
    <content type="text"><![CDATA[我们有一堆非线性数据，要通过神经网络找到他们的关系。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455import tensorflow as tfimport numpy as npimport matplotlib.pyplot as plt# 添加一层神经网络的方法def add_layer(inputs,in_size,out_size,activation_function=None): # 定义神经层的两个变量 Weights = tf.Variable(tf.random_normal([in_size,out_size])) biases = tf.Variable(tf.zeros([1,out_size])+0.1) # 建立模型 Wx_plus_b = tf.matmul(inputs,Weights)+biases # 带入激活函数 if activation_function is None: outputs = Wx_plus_b else: outputs = activation_function(Wx_plus_b) # 返回输出tensor return outputs# 制作数据x_data = np.linspace(-1,1,300)[:,np.newaxis]noise = np.random.normal(0,0.05,x_data.shape)y_data = np.square(x_data)-0.5 + noise# 定义传入数据的placeholderxs = tf.placeholder(tf.float32,[None,1])ys = tf.placeholder(tf.float32,[None,1])# 添加输入层l1 = add_layer(xs,1,10,activation_function=tf.nn.tanh)# 添加输出层prediction = add_layer(l1,10,1)# lossloss =tf.reduce_mean(tf.reduce_sum(tf.square(ys - prediction),reduction_indices=[1]))# 训练train_step = tf.train.GradientDescentOptimizer(0.1).minimize(loss)init = tf.global_variables_initializer()with tf.Session() as sess: sess.run(init) for i in range(1000): sess.run(train_step,feed_dict=&#123;xs:x_data,ys:y_data&#125;) if i%50 == 0: print(sess.run(loss,feed_dict=&#123;xs:x_data,ys:y_data&#125;)) pv = sess.run(prediction,feed_dict=&#123;xs:x_data,ys:y_data&#125;) plt.figure() plt.scatter(x_data,y_data) plt.plot(x_data,pv,'r-',lw=5) plt.show() 以下是每学习50次之后计算的loss，可以看到其数值是不断变小的，这说明我们预测的准确率在提高 0.166237 0.0227031 0.0102089 0.0071321 0.00638495 0.00612547 0.00597071 0.00584495 0.00573187 0.00562693 0.00552828 0.00543492 0.00534622 0.00526172 0.00518108 0.00510404 0.00503038 0.00495989 0.00489241 0.00482777 蓝色的点就是我们的数据，红色的线就是我们拟合出来的线]]></content>
      <categories>
        <category>技术</category>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>tensorflow</tag>
        <tag>机器学习</tag>
        <tag>深度学习</tag>
        <tag>神经网络</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[tensorflow理论学习之tensor]]></title>
    <url>%2F2018%2F01%2F18%2Fpython%2Ftensorflow-tensor%2F</url>
    <content type="text"><![CDATA[TensorFlow中Tensor就是张量的意思。 张量 张量（tensor）理论是数学的一个分支学科，在力学中有重要应用。张量这一术语起源于力学，它最初是用来表示弹性介质中各点应力状态的，后来张量理论发展成为力学和物理学的一个有力的数学工具。张量之所以重要，在于它可以满足一切物理定律必须与坐标系的选择无关的特性。张量概念是矢量概念的推广，矢量是一阶张量。张量是一个可用来表示在一些矢量、标量和其他张量之间的线性关系的多线性函数。在同构的意义下，第零阶张量 （r = 0） 为标量 （Scalar），第一阶张量 （r = 1） 为向量 （Vector）， 第二阶张量 （r = 2） 则成为矩阵 （Matrix）。—《百度百科》 阶在TensorFlow系统中，张量的维数来被描述为阶.但是张量的阶和矩阵的阶并不是同一个概念.张量的阶（有时是关于如顺序或度数或者是n维）是张量维数的一个数量描述. 下表是tensor的阶的说明 阶 数学实例 Python 0 纯量 (只有大小) s = 483 1 向量(大小和方向) v = [1.1, 2.2, 3.3] 2 矩阵(数据表) m = [[1, 2, 3], [4, 5, 6], [7, 8, 9]] 3 3阶张量 (数据立体) t = [[[2], [4], [6]], [[8], [10], [12]], [[14], [16], [18]]] n n阶 (自己想想看) …. 形状和维数下表是tensor的阶与形状和维数的说明 阶 形状 维数 实例 0 [ ] 0-D 一个 0维张量. 一个纯量. 1 [D0] 1-D 一个1维张量的形式[5]. 2 [D0, D1] 2-D 一个2维张量的形式[3, 4]. 3 [D0, D1, D2] 3-D 一个3维张量的形式 [1, 4, 3]. n [D0, D1, … Dn] n-D 一个n维张量的形式 [D0, D1, … Dn]. 数据类型 数据类型 Python 类型 描述 DT_FLOAT tf.float32 32 位浮点数. DT_DOUBLE tf.float64 64 位浮点数. DT_INT64 tf.int64 64 位有符号整型. DT_INT32 tf.int32 32 位有符号整型. DT_INT16 tf.int16 16 位有符号整型. DT_INT8 tf.int8 8 位有符号整型. DT_UINT8 tf.uint8 8 位无符号整型. DT_STRING tf.string 可变长度的字节数组.每一个张量元素都是一个字节数组. DT_BOOL tf.bool 布尔型. DT_COMPLEX64 tf.complex64 由两个32位浮点数组成的复数:实数和虚数. DT_QINT32 tf.qint32 用于量化Ops的32位有符号整型. DT_QINT8 tf.qint8 用于量化Ops的8位有符号整型. DT_QUINT8 tf.quint8 用于量化Ops的8位无符号整型. 常用类型tensorflow中张量（tensor）在我们编程过程中创建模型时主要用到了三种类型： tf.Variable：变量 tf.Constant：常量 tf.Placeholder：占位符 VariableVariable变量，可以理解为在学习的过程中要调整修改的值，也可以理解为模型中需要确定的值。 1234567891011import tensorflow as tf# 创建变量w = tf.Variable(&lt;initial-value&gt;, name=&lt;optional-name&gt;)# 编程中使用变量作为tensory = tf.matmul(w, ...another variable or tensor...) # 给变量重新赋值w.assign(w + 1.0)w.assign_add(1.0) 变量在进入会话（Session）中执行之前时需要初始化的，有两种初始化方法： 1234567# 单独初始化某个变量with tf.Session() as sess: sess.run(w.initializer) # 初始化所有变量 with tf.Session() as sess: sess.run(tf.global_variables_initializer()) ConstantConstant常量，定义之后，在学习的过程的始终都是固定值，可以理解为模型中确定的参数。 123456# 创建一维常量tensor = tf.constant([1, 2, 3, 4, 5, 6, 7]) =&gt; [1 2 3 4 5 6 7]# 创建二维常量tensor = tf.constant(-1.0, shape=[2, 3]) =&gt; [[-1. -1. -1.] [-1. -1. -1.]] PlaceholderPlaceholder占位符，编程中建模时无法确定要输入的数据时，可以用占位符来做临时输入。 重点:placeholder必须通过feed_dict填充之后才能正确执行以下几个方法 Session.run() Tensor.eval() Operation.run() 12345678x = tf.placeholder(tf.float32, shape=(1024, 1024))y = tf.matmul(x, x)with tf.Session() as sess: print(sess.run(y)) # ERROR: will fail because x was not fed. rand_array = np.random.rand(1024, 1024) print(sess.run(y, feed_dict=&#123;x: rand_array&#125;)) # Will succeed.]]></content>
      <categories>
        <category>技术</category>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>tensorflow</tag>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一个使用tensorflow实现的简单的机器学习的例子]]></title>
    <url>%2F2018%2F01%2F17%2Fpython%2Ftensorflow-helloworld%2F</url>
    <content type="text"><![CDATA[一个使用tensorflow实现的简单的机器学习的例子首先我们有一堆数据12x=[x1,x2,...]y=[y1,y2,...] 我们建立了一个线性模型1y = k*x + b 我们想通过这个模型在下次有x出现时来预测y的值，那么我们就要求出k和b的值，通过方程带入x求出y。 下面就是通过tensorflow来建立学习过程 123456789101112131415161718192021222324252627282930import numpy as npimport tensorflow as tf# 通过随机数制作x和y的数据集x_data = np.random.random(100)y_data = 8*x_data+ 1 # 建立变量Weights = tf.Variable(tf.zeros([1]))biases = tf.Variable(tf.zeros([1]))# 计算lossy = Weights * x_data + biasesloss = tf.reduce_mean(tf.square(y-y_data))# 通过梯度下降算法训练optimizer = tf.train.GradientDescentOptimizer(0.5)train = optimizer.minimize(loss) sess = tf.Session()# 初始化变量sess.run(tf.global_variables_initializer())# 训练for step in range(200): sess.run(train) print('k:',sess.run(Weights))print('b:',sess.run(biases))sess.close() k: [ 7.99999809] b: [ 1.00000095] 我们通过结果可以看到k和b很接近我们假设里所设置的值：k=8,b=1]]></content>
      <categories>
        <category>技术</category>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>tensorflow</tag>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[numpy常用方法总结]]></title>
    <url>%2F2018%2F01%2F09%2Fpython%2Fnumpy%2F</url>
    <content type="text"><![CDATA[numpy的中文文档 1import numpy as np 12345678arr = np.array([[1,0,0],[0,2,0],[0,0,3]])print('数据:')print(arr) print('数据的形状(shape):',arr.shape) print('数据的大小(size):',arr.size) print('数据的维度(number of dim):',arr.ndim) print('数据的类型(type of data):',arr.dtype) print('每个元素的字节大小(size of item):',arr.itemsize) 数据: [[1 0 0] [0 2 0] [0 0 3]] 数据的形状(shape): (3, 3) 数据的大小(size): 9 数据的维度(number of dim): 2 数据的类型(type of data): int64 每个元素的字节大小(size of item): 8 1234567891011121314151617181920212223242526272829# 数组创建 print('创建一维数组：',np.array([1,2,3])) print('创建二维维数组，并指定类型：',np.array([[1,2,3],[2,3,4]],dtype=np.float32)) print('创建0矩阵:',np.zeros((3,4))) print('创建1矩阵:',np.ones((3,4))) print('创建空矩阵:',np.empty((3,4))) # 有序数列print('创建有序数列:',np.arange(20)) print('创建有序数列，并指定范围和步长:',np.arange(10,20,2)) # 线性数列 print('创建线性数列:',np.linspace(10,20,5))# 随机数列 print('创建随机数列:',np.random.random((2,4))) print('创建均匀分布的随机样本:',np.random.rand(3,2))print('创建标准正态分布的随机样本:',np.random.randn(3,2)) print('创建整数的随机样本:',np.random.randint(5, size=(2, 4)))# 随机数列 print('按结构创建:')print(np.empty_like(arr))print(np.ones_like(arr))print(np.zeros_like(arr))print('通过方法创建：') print(np.fromfunction(lambda i, j: i + j, (3, 3), dtype=int)) 创建一维数组： [1 2 3] 创建二维维数组，并指定类型： [[ 1. 2. 3.] [ 2. 3. 4.]] 创建0矩阵: [[ 0. 0. 0. 0.] [ 0. 0. 0. 0.] [ 0. 0. 0. 0.]] 创建1矩阵: [[ 1. 1. 1. 1.] [ 1. 1. 1. 1.] [ 1. 1. 1. 1.]] 创建空矩阵: [[ 1. 1. 1. 1.] [ 1. 1. 1. 1.] [ 1. 1. 1. 1.]] 创建有序数列: [ 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19] 创建有序数列，并指定范围和步长: [10 12 14 16 18] 创建线性数列: [ 10. 12.5 15. 17.5 20. ] 创建随机数列: [[ 0.33749064 0.10923476 0.85146845 0.18452114] [ 0.74289369 0.07023398 0.92065584 0.90198327]] 创建均匀分布的随机样本: [[ 0.82113554 0.59369178] [ 0.74653088 0.27335578] [ 0.53047287 0.32964674]] 创建标准正态分布的随机样本: [[-1.00132373 0.31760582] [-1.84957782 -2.23647493] [ 0.98775302 -0.8335129 ]] 创建整数的随机样本: [[4 3 0 3] [4 2 3 1]] 按结构创建: [[0 0 0] [0 0 0] [0 0 0]] [[1 1 1] [1 1 1] [1 1 1]] [[0 0 0] [0 0 0] [0 0 0]] 通过方法创建： [[0 1 2] [1 2 3] [2 3 4]] 1234567891011121314# 数组运算a = np.array([10,20,30,40])b = np.arange(4)print('a:',a,'b:',b) print('a+b：',a+b)print('a-b：',a-b)print('a*b：',a*b)print('a/(b+1)：',a/(b+1))print('次方b**2：',b**2)print('比较b&lt;2：',b&lt;2)print('比较b==2：',b==2) print('修改shape：')print(b.reshape(4,1)) print('矩阵乘：',np.dot(a,b.reshape(4,1))) a: [10 20 30 40] b: [0 1 2 3] a+b： [10 21 32 43] a-b： [10 19 28 37] a*b： [ 0 20 60 120] a/(b+1)： [ 10. 10. 10. 10.] 次方b**2： [0 1 4 9] 比较b&lt;2： [ True True False False] 比较b==2： [False False True False] 修改shape： [[0] [1] [2] [3]] 矩阵乘： [200] 12345678910# 运算r = np.random.randint(10,size=(3,4))print(r)print('求和：',np.sum(r))print('最大值：',np.max(r))print('最小值：',np.min(r)) print('按列求和：',np.sum(r,axis=0))print('按行取最大：',np.max(r,axis=1))print('所有值取最小：',np.min(r,axis=None)) [[9 0 1 5] [5 2 9 6] [4 9 4 9]] 求和： 63 最大值： 9 最小值： 0 按列求和： [18 11 14 20] 按行取最大： [9 9 9] 所有值取最小： 0 1234567891011121314151617181920212223242526272829303132# 索引r = np.random.randint(20,size=(3,4))print(r) print('最小值索引:',np.argmin(r)) print('最大值索引:',np.argmax(r)) print('平均数:',np.average(r)) print('中位数:',np.median(r)) print('累加数列:',np.cumsum(r)) print('差值数列:')print(np.diff(r)) print('非零索引:',np.nonzero(r))a = np.random.randint(20,size=(3,4))print('a:',a)print('a[0]:',a[0])print('a[0,:]:',a[0,:])print('a[:,0]:',a[:,0])print('a[0:2,0]:',a[0:2,0])print('a[2,1]:',a[2,1])print('a.item(9):',a.item(9))print('遍历列:')for column in a.T: print(column) print('一维化:') print(a.flatten()) print('遍历值:') for item in a.flat: print(item) [[19 9 11 17] [ 1 4 1 8] [ 1 18 2 0]] 最小值索引: 11 最大值索引: 0 平均数: 7.58333333333 中位数: 6.0 累加数列: [19 28 39 56 57 61 62 70 71 89 91 91] 差值数列: [[-10 2 6] [ 3 -3 7] [ 17 -16 -2]] 非零索引: (array([0, 0, 0, 0, 1, 1, 1, 1, 2, 2, 2]), array([0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2])) a: [[ 4 12 15 11] [ 0 17 11 19] [ 0 6 15 17]] a[0]: [ 4 12 15 11] a[0,:]: [ 4 12 15 11] a[:,0]: [4 0 0] a[0:2,0]: [4 0] a[2,1]: 6 a.item(9): 6 遍历列: [4 0 0] [12 17 6] [15 11 15] [11 19 17] 一维化: [ 4 12 15 11 0 17 11 19 0 6 15 17] 遍历值: 4 12 15 11 0 17 11 19 0 6 15 17 12345678910111213a = np.random.randint(20,size=(3,4))print(a)print("矩阵排序：")print(np.sort(a))print(np.sort(a,axis=0))print(np.sort(a,axis=1))print("矩阵转置：")print(a.T)print(np.transpose(a))print("截断矩阵值：")print(np.clip(a,5,10)) [[ 4 6 14 7] [ 6 19 14 17] [ 5 7 18 3]] 矩阵排序： [[ 4 6 7 14] [ 6 14 17 19] [ 3 5 7 18]] [[ 4 6 14 3] [ 5 7 14 7] [ 6 19 18 17]] [[ 4 6 7 14] [ 6 14 17 19] [ 3 5 7 18]] 矩阵转置： [[ 4 6 5] [ 6 19 7] [14 14 18] [ 7 17 3]] [[ 4 6 5] [ 6 19 7] [14 14 18] [ 7 17 3]] 截断矩阵值： [[ 5 6 10 7] [ 6 10 10 10] [ 5 7 10 5]] 12345678910111213# 合并a = np.array([[1,1],[1,1]])b = np.array([[2,2],[2,2]])print('纵向合并:')print(np.vstack((a,b)))print('横向合并:')print(np.hstack((a,b)))print('纵向合并:')print(np.concatenate((a,b,a,b),axis=0))print('横向合并:')print(np.concatenate((a,b,a,b),axis=1)) 纵向合并: [[1 1] [1 1] [2 2] [2 2]] 横向合并: [[1 1 2 2] [1 1 2 2]] 纵向合并: [[1 1] [1 1] [2 2] [2 2] [1 1] [1 1] [2 2] [2 2]] 横向合并: [[1 1 2 2 1 1 2 2] [1 1 2 2 1 1 2 2]] 1234# 数列转矩阵a = np.array([1,1,1])print(a[np.newaxis,:])print(a[:,np.newaxis]) [[1 1 1]] [[1] [1] [1]] 1234567891011# 数据分割a = np.arange(12).reshape(3,4)print(a)print('按行分割:')print(np.split(a,3,axis=0))print('按列分割:')print(np.split(a,2,axis=1))print('按列指定分割:') print(np.split(a,(1,1,2),axis=1))print('按列自动分割:') print(np.array_split(a,3,axis=1)) [[ 0 1 2 3] [ 4 5 6 7] [ 8 9 10 11]] 按行分割: [array([[0, 1, 2, 3]]), array([[4, 5, 6, 7]]), array([[ 8, 9, 10, 11]])] 按列分割: [array([[0, 1], [4, 5], [8, 9]]), array([[ 2, 3], [ 6, 7], [10, 11]])] 按列指定分割: [array([[0], [4], [8]]), array([], shape=(3, 0), dtype=int64), array([[1], [5], [9]]), array([[ 2, 3], [ 6, 7], [10, 11]])] 按列自动分割: [array([[0, 1], [4, 5], [8, 9]]), array([[ 2], [ 6], [10]]), array([[ 3], [ 7], [11]])] 123456789# copya = np.arange(4)b = ac = ad = bprint(a,b,c,d)a[0] = 10print(a,b,c,d) [0 1 2 3] [0 1 2 3] [0 1 2 3] [0 1 2 3] [10 1 2 3] [10 1 2 3] [10 1 2 3] [10 1 2 3] 1234567# deep copya = np.arange(4)b = a.copy() print(a,b)a[0] = 10print(a,b) [0 1 2 3] [0 1 2 3] [10 1 2 3] [0 1 2 3]]]></content>
      <categories>
        <category>技术</category>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>numpy</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据可视化基本图形]]></title>
    <url>%2F2018%2F01%2F08%2Fdatamining%2F%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96%E5%9F%BA%E6%9C%AC%E5%9B%BE%E5%BD%A2%2F</url>
    <content type="text"><![CDATA[数据可视化中最基本的图形有六种： 条形图 折线图 散点图 气泡图 饼图 雷达图 条形图用于二位数据之间的对比，展示的重点是数据的差异 折线图用于二位数据之间的对比，展示的重点是数据的趋势走向 散点图可以用于对比二位数据，也可以用于对比三维数据，展示的重点是数据的分布 气泡图散点图的升级版，可以通过气泡的大小展示数据的重要度 饼图不宜展示过多的数据，一般不超过5个扇形，展示的重点是数据比例 雷达图能最大维度的展示数据信息]]></content>
      <categories>
        <category>技术</category>
        <category>数据挖掘</category>
      </categories>
      <tags>
        <tag>数据挖掘</tag>
        <tag>数据可视化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ssh免密登录]]></title>
    <url>%2F2018%2F01%2F04%2Flinux%2Fssh%E5%85%8D%E5%AF%86%E7%99%BB%E5%BD%95%2F</url>
    <content type="text"><![CDATA[比如需要机器A不通过密码直接登录机器B 首先要在A机器上执行ssh-keygen命令生成密钥然后将id_rsa.pub里的内容复制到B机器的~/.ssh/authorized_keys中 然后A就可以登录B了，就是这么简单 配置多台机器之见免密登录123456789$ mkdir .ssh$ chmod 700 .ssh$ ssh-keygen -t rsa$ cat id_rsa.pub &gt;&gt; authorized_keys$ chmod 600 authorized_keys# 将所有机器的密钥全部弄到一台机器上$ cat ~/.ssh/id_rsa.pub | ssh Hadoop@Master 'cat &gt;&gt; ~/.ssh/authorized_keys'# 然后将authorized_keys文件给所有节点分发一份$ scp -r authorized_keys hadoop@Slave:~/.ssh/]]></content>
      <categories>
        <category>技术</category>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hadoop的安装与配置]]></title>
    <url>%2F2017%2F12%2F19%2Fbigdata%2Fhadoop%2F</url>
    <content type="text"><![CDATA[本文的Hadoop版本以2.8版本为准 Hadoop官方网站地址：http://hadoop.apache.org/Hadoop下载页面地址：http://hadoop.apache.org/releases.html 下载页中source是源码下载，下载后文件名为：hadoop-2.8.0-src.tar.gzbinary是编译好的，下载后文件名为：hadoop-2.8.0.tar.gz我们这里下载直接编译好的包。 Hadoop目录结构解压后文件目录如下1234567891011LICENSE.txtNOTICE.txtREADME.TXTbinetcincludeliblibexeclogssbinshare 前三个txt文件不多说了bin：这个文件里是命令脚本并且分linux和window（*.cmd）两个版本etc/hadoop：这里面是hadoop的相关配置和一些程序执行初期的环境设置脚本，同样有两个系统的版本include：这里面是C++的头文件lib/native：这里面就是编译好的hadoop和hdfs等相关的底层库libexec：这里也是两个系统的脚本sbin：这里面是各种启动、停止的脚本share：hadoop体系内的各个模块的jar包和文档 部署主要分为以下几步： 机器的环境设置 时间设置 防火墙设置 selinux设置 修改HostName Host设置 免密登录 JDK的安装 HDFS的配置设置 配置core-site.xml 配置hdfs-site.xml 配置slaves Yarn的配置 配置mapred-site.xml 配置yarn-site.xml Hadoop 所有节点部署Hadoop 修改HostName1$ vim /etc/sysconfig/network 设置Host1$ vim /etc/hosts 123192.168.0.1 Master192.168.0.2 Slave1192.168.0.3 Slave2 所有机器上都要这么设置尽量使用内网地址 配置SSH免密码通信123456789$ mkdir .ssh$ chmod 700 .ssh$ ssh-keygen -t rsa$ cat id_rsa.pub &gt;&gt; authorized_keys$ chmod 600 authorized_keys# 将所有机器的密钥全部弄到一台机器上$ cat ~/.ssh/id_rsa.pub | ssh Hadoop@Master 'cat &gt;&gt; ~/.ssh/authorized_keys'# 然后将authorized_keys文件给所有节点分发一份$ scp -r authorized_keys hadoop@Slave:~/.ssh/ 配置core-site.xml fs.defaultFSNameNode URI hdfs://host:port/ 配置hdfs-site.xmldfs.namenode.name.dirPath on the local filesystem where the NameNode stores the namespace and transactions logs persistently. If this is a comma-delimited list of directories then the name table is replicated in all of the directories, for redundancy. dfs.datanode.data.dirComma separated list of paths on the local filesystem of a DataNode where it should store its blocks. If this is a comma-delimited list of directories, then data will be stored in all named directories, typically on different devices. 详细设计可以看官方文档：http://hadoop.apache.org/docs/r2.8.0/hadoop-project-dist/hadoop-common/ClusterSetup.html HDFS的操作命令：http://hadoop.apache.org/docs/r2.8.0/hadoop-project-dist/hadoop-common/FileSystemShell.html 格式化HDFS$ hdfs namenode -format$ start-dfs.sh dfs相关配置dfs.permissions = true如果是 true，则打开前文所述的权限系统。如果是 false，权限检查 就是关闭的，但是其他的行为没有改变。这个配置参数的改变并不改变文件或目录的模式、所有者和组等信息。不管权限模式是开还是关，chmod，chgrp 和 chown 总是 会检查权限。这些命令只有在权限检查背景下才有用，所以不会有兼容性问题。这样，这就能让管理员在打开常规的权限检查之前可以可靠地设置文件的所有者和权限。dfs.web.ugi = webuser,webgroupWeb服务器使用的用户名。如果将这个参数设置为超级用户的名称，则所有Web客户就可以看到所有的信息。如果将这个参数设置为一个不使用的用户，则Web客户就只能访问到“other”权限可访问的资源了。额外的组可以加在后面，形成一个用逗号分隔的列表。dfs.permissions.supergroup = supergroup超级用户的组名。dfs.upgrade.permission = 777升级时的初始模式。文件永不会被设置x权限。在配置文件中，可以使用十进制数51110。dfs.umask = 022umask参数在创建文件和目录时使用。在配置文件中，可以使用十进制数1810。 1hadoop dfsadmin -safemode leave]]></content>
      <categories>
        <category>技术</category>
        <category>hadoop</category>
      </categories>
      <tags>
        <tag>大数据</tag>
        <tag>hadoop</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[轻量级Linux - Alpine]]></title>
    <url>%2F2017%2F12%2F19%2Flinux%2Falpine%2F</url>
    <content type="text"><![CDATA[Alpine Linux 是一个社区开发的面向安全应用的轻量级Linux发行版。 SMALL 它采用了musl libc和busybox以减小系统的体积和运行时的资源消耗。 SIMPLE 提供了自己的包管理工具apk。 SECURE Linux的内核都打了grsecurity/PaX补丁以增强系统的安全性，并且所有的程序都编译为Position Independent Executables (PIE) 。 关于PIE 在计算机领域中，地址无关代码 (英文: position-independent code，缩写为PIC)，又称地址无关可执行文件 (英文: position-independent executable，缩写为PIE) ，是指可在主存储器中任意位置正确地运行，而不受其绝对地址影响的一种机器码。PIC广泛使用于共享库，使得同一个库中的代码能够被加载到不同进程的地址空间中。PIC还用于缺少内存管理单元的计算机系统中， 使得操作系统能够在单一的地址空间中将不同的运行程序隔离开来。 地址无关代码能够在不做修改的情况下被复制到内存中的任意位置。这一点不同于重定位代码，因为重定位代码需要经过链接器或加载器的特殊处理才能确定合适的运行时内存地址。 地址无关代码需要在源代码级别遵循一套特定的语义，并且需要编译器的支持。那些引用了绝对内存地址的指令（比如绝对跳转指令）必须被替换为PC相对寻址指令。这些间接处理过程可能导致PIC的运行效率下降，但是目前大多数处理器对PIC都有很好的支持，使得这效率上的这一点点下降基本可以忽略。 —–引用自维基百科 关于muslalpine系统采用的底层库为musl，不同于我们常用的glibc库，最大的特点就是轻量级，因此我们在glibc上编译出来的执行文件在alpine上是无法运行的。 关于busyboxBusyBox 是一个集成了一百多个最常用Linux命令和工具的软件。BusyBox 包含了一些简单的工具，例如ls、cat和echo等等，还包含了一些更大、更复杂的工具，例grep、find、mount以及telnet。有些人将 BusyBox 称为 Linux 工具里的瑞士军刀。简单的说BusyBox就好像是个大工具箱，它集成压缩了 Linux 的许多工具和命令，也包含了 Android 系统的自带的shell。 alpine的包管理系统apkThe apk tool has the following applets: 命令 说明 add Add new packages to the running system del Delete packages from the running system fix Attempt to repair or upgrade an installed package update Update the index of available packages info Prints information about installed or available packages search Search for packages or descriptions with wildcard patterns upgrade Upgrade the currently installed packages cache Maintenance operations for locally cached package repository version Compare version differences between installed and available packages index create a repository index from a list of packages fetch download (but not install) packages audit List changes to the file system from pristine package install state verify Verify a package signature apk中包含的package可以在官方网站上查 时区设置的例子alpine是不包含时区的，只有标准时区，如果要改变时区，就要安装时间的package：1apk add tzdata 然后按照linux的设置来配置时区：123TZ=Asia/Shanghaiecho $TZ &gt; /etc/timezoneln -snf /usr/share/zoneinfo/$TZ /etc/localtime]]></content>
      <categories>
        <category>技术</category>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>alpine</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[通过进程启动参数分别载入开发、测试、正式环境配置]]></title>
    <url>%2F2017%2F12%2F18%2Fgolang%2Fbeego_env%2F</url>
    <content type="text"><![CDATA[beego的默认配置beego的默认配置文件为 ./conf/app.confbeego本身支持三种section来区分开发、测试、正式三个环境，例如:1234567891011121314appname = beepkghttpaddr = &quot;127.0.0.1&quot;httpport = 9090runmode =&quot;dev&quot;autorender = falserecoverpanic = falseviewspath = &quot;myview&quot;[dev]httpport = 8080[prod]httpport = 8088[test]httpport = 8888 这种配置有以下几个问题： dev,prod,test环境的改变，必须修改配置文件 必须区分通用配置和每个环境的独立配置 我设计的配置方式我们通过进程的启动参数来选择加载的配置文件，代码如下： 12345678910if len(os.Args) &gt; 1 &#123; mode := os.Args[1] if mode == "prod" &#123; beego.LoadAppConfig("ini", "conf/app.prod.conf") &#125; else if mode == "test" &#123; beego.LoadAppConfig("ini", "conf/app.test.conf") &#125; else &#123; beego.LoadAppConfig("ini", "conf/app.conf") &#125;&#125; 通过获取进程的第一个参数字符串来判断环境，这样我们目录结构为： 1234conf ├── app.test.conf ├── app.prod.conf ├── app.conf 这三个文件 正式环境和测试环境就可以这样启动程序 ./appName prod ./appName test 而我们的开发环境还是可以使用beego的工具 bee run -gendoc=true -downdoc=true]]></content>
      <categories>
        <category>技术</category>
        <category>golang</category>
      </categories>
      <tags>
        <tag>golang</tag>
        <tag>beego</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[利用Docker编译golang程序]]></title>
    <url>%2F2017%2F12%2F16%2Fdocker%2F%E5%88%A9%E7%94%A8Docker%E7%BC%96%E8%AF%91golang%E7%A8%8B%E5%BA%8F%2F</url>
    <content type="text"><![CDATA[使用Docker编译部署golang程序我们选型go语言其中有一个原因就是go语言编译完成之后不需要任何依赖就可以在机器上运行，这个有别于php、java、python等其他语言需要运行环境，方便部署。 要编译go语言的程序，首先要有go语言的环境，如果要持续集成我们一般要有专门的编译环境，docker就帮我们解决了这个问题，哪里运行哪里编译却不用部署编译环境。 Docker上有官方的golang镜像，镜像里有完善的golang的环境，所以只要有docker我们就可以在镜像中执行编译。 废话不多说，上干货。流程上主要有两个： 编译流程 部署流程 编译流程我们直接看dockerfile.build1234567891011121314151617181920212223242526# dockerfile.build# 从官方拉取golang镜像FROM golang# 设置编译变量，这里值弄一个项目名称做例子ARG PROJECTNAME # 指定工作目录WORKDIR /go/src # 拉取代码RUN git clone https://git.xxx.cn/group/$PROJECTNAME.git# 进去项目目录WORKDIR /go/src/$PROJECTNAME # 运行拉取依赖的脚本RUN pkg.sh# 执行编译打包RUN go build -ldflags "-s -w"# 将编译完成的文件复制到指定目录RUN mkdir /releaseRUN cp -r ./conf ./data $PROJECTNAME /release 这样在build镜像时，我们就完成了go的编译，我们配合脚本来进一步完善流程。 123456789101112131415161718192021#!/bin/bash # compile.sh PROJECTNAME=$1 # 按照dockerfile.build创建golang_compile镜像docker build -f ./docker/dockerfile.build \ --build-arg PROJECTNAME=$PROJECTNAME \ -t golang_compile . # 运行golang_compile镜像建立containerdocker run -d --name $PROJECTNAME'_compile' golang_compile# 从container中拷贝出编译好的代码docker cp $PROJECTNAME'_compile':/release ./release_$PROJECTNAME# 停止并删除containerdocker rm -f $PROJECTNAME'_compile' 2&gt;/dev/null# 删除golang_compiledocker rmi -f golang_compile 使用时只需要执行下面脚本1compile.sh project_name 然后我们的目录里就会多出一个release_project_name，这里面就是我们编译好的程序。其实，我们可以直接在这个镜像里运行我们的golang程序，那我为什么要分开呢？读者可以思考一下，我先卖个关子。 部署流程直接上dockerfile 1234567891011121314FROM golangMAINTAINER aviyu "aviyu@xxx.com"ARG PROJECTNAME WORKDIR /rootADD ./release_$PROJECTNAME/ /root EXPOSE 8080 ENTRYPOINT ["./project_name","prod"] 当然依旧要配合着脚本来build，这里就不列具体代码了，我简单只说一下脚本里的基础流程： 参数处理 制作镜像：docker build 停止之前的container 运行：docker run 这样我们的编译和部署流程就算完成了。 刚才卖的关子其实最后我们会发现利用golang打包的镜像特别大，golang本身就要700多MB，然后加上我们的程序，好在我们的go get下来的依赖代码因为分了两步进行，没有在部署的镜像里，不然更大，怎么办呢？ 很简单，换一个小一点的镜像，把程序放进去不就行了吗？没错，就是这么简单！具体怎么搞呢，咱们下回分解…]]></content>
      <categories>
        <category>技术</category>
        <category>docker</category>
      </categories>
      <tags>
        <tag>golang</tag>
        <tag>运维</tag>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[利用Docker编译前端项目]]></title>
    <url>%2F2017%2F12%2F14%2Fdocker%2F%E5%88%A9%E7%94%A8Docker%E7%BC%96%E8%AF%91%E5%89%8D%E7%AB%AF%E9%A1%B9%E7%9B%AE%2F</url>
    <content type="text"><![CDATA[利用Docker编译前端项目为什么要用Docker对前端进行编译打包？ 我们的代码存在git等代码管理上是源码存放的 源码要编译成产品环境用的代码需要一定环境 测试服务器和产品服务器不一定具备编译的环境 通过Docker进行变异打包可以减少编译环境的部署工作量 首先，我们的前端开发环境有打包的命令1npm run build 我们来分析一下编译需要的环境。 我们运气不错，目前前端编译打包的工具主要以node为主，在node基础上，有grunt、webpack、gulp等等，所以只要机器上具备node环境即可 利用Dockerfile在docker中建立编译环境1234567891011121314151617181920212223242526272829303132# dockerfile.build# 从官方拉取node镜像FROM node# 设置编译变量ARG BUILD_ARGSARG PROJECTNAME# 指定工作目录WORKDIR /root# 拉取代码RUN git clone github.com/xxxx/project.git# 进去项目目录WORKDIR /root/$PROJECTNAME# 设置阿里源，加速npm下载RUN npm config set registry http://registry.npm.taobao.org/# 安装依赖RUN npm install# 执行编译打包RUN npm run build $BUILD_ARGS# 创建release目录RUN mkdir -p /release# 将编译完成的文件复制到指定目录RUN cp -r ./dist /release/$PROJECTNAME 说明一下：这个镜像就建立了一个 创建环境 拉取代码 安装依赖 执行编译 这样的一个过程。 但是我们创建镜像之后，代码仍旧在镜像内部，我们无法拿到文件下面我们还需要创建这个镜像，并运行，然后拿出代码到指定目录 123456789101112131415161718192021222324#!/bin/bash # node_compile.sh# 项目名称PROJECTNAME=$1ARGS=$2# 按照dockerfile.build创建node_compile镜像docker build -f dockerfile.build \ --build-arg BUILD_ARGS=$ARGS \ --build-arg PROJECTNAME=$PROJECTNAME \ -t node_compile --no-cache .# 运行node_compile镜像建立containerdocker run -d --name $PROJECTNAME node_compile# 从container中拷贝出编译好的代码docker cp $PROJECTNAME:/code/$PROJECTNAME ./release# 停止并删除containerdocker rm -f $PROJECTNAME# 删除node_compiledocker rmi -f node_compile 执行完毕之后，就发现我们的当前目录里多了release目录，里面存放的就是我们编译完成的文件 然后，我们就可以使用这些release文件制作生产环境的镜像]]></content>
      <categories>
        <category>技术</category>
        <category>docker</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>前端</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Registry的安装与使用]]></title>
    <url>%2F2017%2F12%2F13%2Fdocker%2Fregistry%2FRegistry%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[Registry的安装与使用registry的安装安装的话，只要有了docker环境，只需要运行registry镜像即可，例如： 1234567891011121314151617docker run -d \-p 6666:5000 \--restart=always \--name registry2 \# 设置本地的仓储目录-v /data/docker/registry:/var/lib/registry \# 映射密钥的地址-v /data/docker/certs:/certs \# 启用Https的设置-e REGISTRY_HTTP_ADDR=0.0.0.0:443 \-e REGISTRY_HTTP_TLS_CERTIFICATE=/certs/docker.crt \-e REGISTRY_HTTP_TLS_KEY=/certs/docker.key \# 允许调用DELETE接口-e REGISTRY_STORAGE_DELETE_ENABLED=true \# 开放Https的端口-p 443:443 \registry:2 registry的使用如果是自制证书，客户端拉取镜像的时候会报错： x509: certificate is valid for docker 这时需要客户端将机器的域名配置成insecure的 在目录 /etc/docker/daemon.json 添加下面的json字符串： 123&#123; "insecure-registries" : ["myregistrydomain.com:5000"]&#125; 查看镜像 12/v2/_catalog/v2/&lt;name&gt;/tags/list 查看 digest 1curl --header "Accept: application/vnd.docker.distribution.manifest.v2+json" -I -X GET http://domain/v2/&lt;name&gt;/manifests/&lt;tag&gt;]]></content>
      <categories>
        <category>技术</category>
        <category>docker</category>
        <category>registry</category>
      </categories>
      <tags>
        <tag>运维</tag>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker的安装与使用]]></title>
    <url>%2F2017%2F12%2F12%2Fdocker%2FDocker%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[Docker的安装与使用在2017年的3月1号之后，Docker分为ce和ee两个版本，ee是企业版本，强化了安全性。 Docker的安装1.Centos7通过yum安装官方docker-ce1234567891011yum install -y yum-utils \ device-mapper-persistent-data \ lvm2yum-config-manager \ --add-repo \ https://download.docker.com/linux/centos/docker-ce.repoyum install -y docker-cesystemctl start docker 2.配置对外接口1vi /usr/lib/systemd/system/docker.service 修改12[Service]ExecStart=/usr/bin/dockerd -H tcp://0.0.0.0:2375 -H unix://var/run/docker.sock 这里启用了两个host，第一个是供外接调用的接口；第二个是本地使用的socket，即docker命令使用的 注意修改默认端口[2375]，容易被人试探出来，启动挖矿镜像，占用机器资源 重启12systemctl daemon-reloadsystemctl restart docker Docker的使用常用命令1234docker imagesdocker ps -adocker rm -fdocker rmi -f Dockerfile]]></content>
      <categories>
        <category>技术</category>
        <category>docker</category>
      </categories>
      <tags>
        <tag>运维</tag>
        <tag>docker</tag>
      </tags>
  </entry>
</search>
